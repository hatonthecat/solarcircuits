R# solarcircuits
Study Material from introductory college texts to advanced and applied physics

![image](https://github.com/user-attachments/assets/318fb998-c42c-4033-b8ee-bd897ead547b)

![image](https://github.com/user-attachments/assets/e71cecb0-35e6-48ca-b4cc-6724319a6c76)

Manuscript of Isaac Newton's Opticks: https://cudl.lib.cam.ac.uk/view/MS-ADD-03970/1

https://www.gutenberg.org/cache/epub/33504/pg33504-images.html

https://www.e-rara.ch/zut/content/titleinfo/3266497

https://en.wikipedia.org/wiki/Opticks#External_links

https://en.wikipedia.org/wiki/Opticks#Opticks_and_the_Principia

"Unlike the Principia, Opticks is not developed using the geometric convention of propositions proved by deduction from either previous propositions, lemmas or first principles (or axioms). Instead, axioms define the meaning of technical terms or fundamental properties of matter and light, and the stated propositions are demonstrated by means of specific, carefully described experiments. The first sentence of Book I declares "My Design in this Book is not to explain the Properties of Light by Hypotheses, but to propose and prove them by Reason and Experiments. In an Experimentum crucis or "critical experiment" (Book I, Part II, Theorem ii), Newton showed that the color of light corresponded to its "degree of refrangibility" (angle of refraction), and that this angle cannot be changed by additional reflection or refraction or by passing the light through a coloured filter.

The work is a vade mecum of the experimenter's art, displaying in many examples how to use observation to propose factual generalisations about the physical world and then exclude competing explanations by specific experimental tests. Unlike the Principia, which vowed Non fingo hypotheses or "I make no hypotheses" outside the deductive method, the Opticks develops conjectures about light that go beyond the experimental evidence: for example, that the physical behaviour of light was due its "corpuscular" nature as small particles, or that perceived colours were harmonically proportioned like the tones of a diatonic musical scale."

---

![image](https://github.com/user-attachments/assets/7c562b35-88c9-4d89-9489-33e75823c0c3)

https://astro1.panet.utoledo.edu/~ljc/PE_eng.pdf

"A heuristic[1] or heuristic technique (problem solving, mental shortcut, rule of thumb)[2][3][4][5] is any approach to problem solving that employs a pragmatic method that is not fully optimized, perfected, or rationalized, but is nevertheless "good enough" as an approximation or attribute substitution.[6][7] Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution.[8][9] Heuristics can be mental shortcuts that ease the cognitive load of making a decision.[10][11][12]

Heuristic reasoning is often based on induction, or on analogy[.] [...] Induction is the process of discovering general laws [...] Induction tries to find regularity and coherence [...] Its most conspicuous instruments are generalization, specialization, analogy. [...] Heuristic discusses human behavior in the face of problems [...that have been] preserved in the wisdom of proverbs.[13]

— George Pólya, How to Solve It"

https://en.wikipedia.org/wiki/Heuristic

---

https://www.gutenberg.org/ebooks/33504.epub3.images (excerpt with proofread section of above image included below)

"Credits: Produced by Suzanne Lybarger, steve harris, Josephine
Paolucci and the Online Distributed Proofreading Team at
http://www.pgdp.net.

*** START OF THE PROJECT GUTENBERG EBOOK OPTICKS ***
OPTICKS:
OR, A
TREATISE
OF THE
Reflections, Refractions,
Inflections and Colours
OF
LIGHT.
The Fourth Edition, corrected.
By Sir ISAAC NEWTON, Knt.
LONDON:
Printed for William Innys at the West-End of St. Paul's. Mdccxxx.
TITLE PAGE OF THE 1730 EDITION

SIR ISAAC NEWTON'S ADVERTISEMENTS
Advertisement I
Part of the ensuing Discourse about Light was written at the Desire of some Gentlemen of the Royal-Society, in the Year 1675, and then sent to their Secretary, and read at their Meetings, and the rest was added about twelve Years after to complete the Theory; except the third Book, and the last Proposition of the Second, which were since put together out of scatter'd Papers. To avoid being engaged in Disputes about these Matters, I have hitherto delayed the printing, and should still have delayed it, had not the Importunity of Friends prevailed upon me. If any other Papers writ on this Subject are got out of my Hands they are imperfect, and were perhaps written before I had tried all the Experiments here set down, and fully satisfied my self about the Laws of Refractions and Composition of Colours. I have here publish'd what I think proper to come abroad, wishing that it may not be translated into another Language without my Consent.

The Crowns of Colours, which sometimes appear about the Sun and Moon, I have endeavoured to give an Account of; but for want of sufficient Observations leave that Matter to be farther examined. The Subject of the Third Book I have also left imperfect, not having tried all the Experiments which I intended when I was about these Matters, nor repeated some of those which I did try, until I had satisfied my self about all their Circumstances. To communicate what I have tried, and leave the rest to others for farther Enquiry, is all my Design in publishing these Papers.

In a Letter written to Mr. Leibnitz in the year 1679, and published by Dr. Wallis, I mention'd a Method by which I had found some general Theorems about squaring Curvilinear Figures, or comparing them with the Conic Sections, or other the simplest Figures with which they may be compared. And some Years ago I lent out a Manuscript containing such Theorems, and having since met with some Things copied out of it, I have on this Occasion made it publick, prefixing to it an Introduction, and subjoining a Scholium concerning that Method. And I have joined with it another small Tract concerning the Curvilinear Figures of the Second Kind, which was also written many Years ago, and made known to some Friends, who have solicited the making it publick.

I. N.

April 1, 1704.

Advertisement II
In this Second Edition of these Opticks I have omitted the Mathematical Tracts publish'd at the End of the former Edition, as not belonging to the Subject. And at the End of the Third Book I have added some Questions. And to shew that I do not take Gravity for an essential Property of Bodies, I have added one Question concerning its Cause, chusing to propose it by way of a Question, because I am not yet satisfied about it for want of Experiments.

I. N.

July 16, 1717.

Advertisement to this Fourth Edition
This new Edition of Sir Isaac Newton's Opticks is carefully printed from the Third Edition, as it was corrected by the Author's own Hand, and left before his Death with the Bookseller. Since Sir Isaac's Lectiones Opticæ, which he publickly read in the University of Cambridge in the Years 1669, 1670, and 1671, are lately printed, it has been thought proper to make at the bottom of the Pages several Citations from thence, where may be found the Demonstrations, which the Author omitted in these Opticks.

[Pg 1]

THE FIRST BOOK OF OPTICKS
PART I.
My Design in this Book is not to explain the Properties of Light by Hypotheses, but to propose and prove them by Reason and Experiments: In order to which I shall premise the following Definitions and Axioms.

DEFINITIONS
DEFIN. I.

By the Rays of Light I understand its least Parts, and those as well Successive in the same Lines, as Contemporary in several Lines. For it is manifest that Light consists of Parts, both Successive and Contemporary; because in the same place you may stop[Pg 2] that which comes one moment, and let pass that which comes presently after; and in the same time you may stop it in any one place, and let it pass in any other. For that part of Light which is stopp'd cannot be the same with that which is let pass. The least Light or part of Light, which may be stopp'd alone without the rest of the Light, or propagated alone, or do or suffer any thing alone, which the rest of the Light doth not or suffers not, I call a Ray of Light.

---

https://iopscience.iop.org/article/10.1088/1755-1315/510/2/022017

"IOP Conference Series: Earth and Environmental Science

"Low-voltage cold-start circuit for energy harvesting suitable for indoor sunlight
Jiaju Pan1, Xinning liu1 and Dengbang Yu1

Published under licence by IOP Publishing Ltd
IOP Conference Series: Earth and Environmental Science, Volume 510, 1. Energy Engineering and Power Engineering
Citation Jiaju Pan et al 2020 IOP Conf. Ser.: Earth Environ. Sci. 510 022017
DOI 10.1088/1755-1315/510/2/022017

This paper proposes a low-voltage cold-start circuit suitable for indoor sunlight energy harvesting in TSMC 40nm CMOS process. The circuit can work normally when the input voltage is as low as 200mV and is compatible with a wide input power range. "

![image](https://github.com/user-attachments/assets/efeb9cae-12d8-4730-947d-477df487fe8d)

https://astro1.panet.utoledo.edu/~ljc/PE_eng.pdf 

https://pubs.aip.org/aapt/ajp/article-abstract/33/5/367/531453/Einstein-s-Proposal-of-the-Photon-Concept-a?redirectedFrom=fulltext
"Einstein's Proposal of the Photon Concept—a Translation of the Annalen der
Physik Paper of 1905
A. B. Arons and M. B. Peppard"

Einstein's Photon Proposal paper in 1905 suggested that the incidence light is proportional to the amount of energy it can excite -applied to a p-n junction, the bandgap wouuld translate into current. With ever more interest in energy harvesting devices, developing the lowest illuminescent cold start enables the highest efficiency in running a circuit, albeit with variables such as a movable object.

In a way, he also predicted the amorphous silicon cells https://en.wikipedia.org/wiki/Amorphous_silicon (although George Cove was already demonstrating this in the early 1900s: https://theconversation.com/if-the-first-solar-entrepreneur-hadnt-been-kidnapped-would-fossil-fuels-have-dominated-the-20th-century-the-way-they-did-215300)

https://en.wikipedia.org/wiki/Amorphous_silicon#/media/File:Solar_calculator_casio_fx115ES_crop.jpg

![640px-Solar_calculator_casio_fx115ES_crop](https://github.com/user-attachments/assets/724943bc-bae3-4aa0-8c72-aac5a61b6585)

![image](https://github.com/user-attachments/assets/3c5e381e-307e-4ead-b9d1-65163bb7e171)

https://e-peas.com/product/aem10920-high-efficiency-photovoltaic-source-pmic-for-rcu-and-kbd-applications/

Vin
0.14V to 3.2V
5VDC opt.input
Cold start
275 mW / 5 μW
Pin
3µW to 550mW
Pout
20 mA @ 1.2/1.8 V and 80 mA @ 1.8-4.1 V
Source Regulation
MPP Tracking
Package
QFN24 4 x 4 mm

![image](https://github.com/user-attachments/assets/de90684a-cf53-4e02-91e7-f6a1e8d646c0)

https://www.acs.org/education/chemmatters/past-issues/archive-2013-2014/how-a-solar-cell-works.html

![image](https://github.com/user-attachments/assets/85661c5b-def8-4921-bd35-884bf6bd0e6f)

Figure 1. Schematic representation of a solar cell, showing the n-type and p-type layers, with a close-up view of the depletion zone around the junction between the n-type and p-type layers.
Anthony Fernandez

![image](https://github.com/user-attachments/assets/39f7c247-009a-44b8-bdf5-ae9a837b88af)

A solar chip with a portable battery/capacitor is, no longer stationary (in the rooftop sense of stationary)

not to be confused with IKAROS:

![image](https://github.com/user-attachments/assets/f963061f-b69b-478a-956b-db792cc301be)
https://en.wikipedia.org/wiki/IKAROS

10/15/2024
--

https://www.librarything.com/work/83668/book/273452866

"Introduction to Electrodynamics- by David J. Griffiths (Author)" 5th Edition out, 4th Edition excellent.
https://www.amazon.com/exec/obidos/ASIN/1108420419/ref=nosim/librarythin06-20

Goal of Solar Circuit:
--

![image](https://github.com/user-attachments/assets/4ccec990-f17a-4f35-846a-7885d769271f)

https://www.st.com/content/st_com/en/about/innovation---technology/FD-SOI.html

https://islped.org/2014/files/ISLPED2014_FD_SOI_Philippe_Flatresse_STMicroelectronics.pdf 


1K of DRAM is ~1024 transistors, but 1K of SRAM is 6144-8192 (or possibly 10T/1C)~10K.

Thus a 386 might use 275,000 transistors, but to run Windows 95, it'd need at least 4,500,000 transistors (+4MB). More than I thought.

Developing a SoM with that much integrated DRAM would be interesting. If I can calculate how many nodes fit inside 1mm x 1mm at 22nm, I could determine the minimum cost.

https://www.cmc.ca/globalfoundries-22fdx-fdsoi-22-nm/

$24,999 for 1mm x 1mm (academic only)

$17,999 (1mm x 9mm) minimum = $161,991 USD. (Also 3mm x 3mm). I've never calculated units to the square very well. Sometimes I don't carry the right unit or number over. 

It's a better deal for 22nm compared to Skywater's 130nm, $10,000 Caravel. (Muse in NL) has some 65nm prices too. Still, it might be possible to manufacture 4MB+ 386 under 1mm x 1mm.

My Pentium was 3.1million at 600nm (or 800nm), plus 8MB, plus 512K-1MB VRAM. To make it a single chip, it'd be 3.1 million, plus whatever cache on board (486 had 8KB), so that's around 12.2 million transistors to make the system in a package/(single board computer like the Raspberry Pi). And it'd all be solar powerable...

But could it fit in 1mm^2?

The Haswell E at 22nm is 2.6 billion transistors in 355 mm^2. Dividing 2.6b/ 355 and I get 7.32million transistors:
https://en.m.wikipedia.org/wiki/Transistor_count (or should I do the square root= ~18 x 18)?

That can't be right, right? 

This column matches roughly with that estimate:

![image](https://github.com/user-attachments/assets/2213f815-0e59-4b21-9b96-997aa015a54f)

![image](https://github.com/user-attachments/assets/eeebaec5-a810-43d4-b6b9-f4c41599113c)
The Xbox One seems to have the highest density at 28nm- 13million transistors in 1 mm^2. The z13 also has 3m more transistors than the Haswell, with 10m transistors. Thus a 1.2m 486 and an 8MB RAM could fit in a 1mm^2 die size (or even a pentium + 8MB, if one counts the XBox one density.)

But that suggests I can fit a Pentium with 8MB DRAM.in 2mm^2 or a 386 with 4MB RAM in 1mm ^2..

AMD Zen CCX (core complex unit: 4 cores, 8 MB L3 cache)	1,400,000,000[111]	2017	AMD	14 nm
(GF 14LPP)	44 mm2	31,800,000 1.4b/ 44 = 31.818 million transistors at 14nm. A 3 million transistor Pentium and 24MB of RAM could fit. 

On DRAM: 
https://electronics.stackexchange.com/questions/175615/why-is-ram-not-put-on-the-cpu-chip

"Intel's Haswell (or at least those products that incorporate the Iris Pro 5200 GPU) and IBM's POWER7 and POWER8 all include embedded DRAM, "eDRAM".

One important issue that has led eDRAM not to be common until recently is that the DRAM fabrication process is not inherently compatible with logic processes, so that extra steps must be included (which increase cost and decrease yield) when eDRAM is desired. So, there must be a compelling reason for wanting to incorporate it in order to offset this economic disadvantage. Alternatively, DRAM can be placed on a separate die that is manufactured independently of, but then integrated onto the same package as, the CPU. This provides most of the benefits of locality without the difficulties of manufacturing the two in a truly integrated way.

Another problem is that DRAM is not like SRAM in that it does not store its contents indefinitely while power is applied, and reading it also destroys the stored data, which must be written back afterwards. Hence, it has to be refreshed periodically and after every read. And, because a DRAM cell is based on a capacitor, charging or discharging it sufficiently that leakage will not corrupt its value before the next refresh takes some finite amount of time. This charging time is not required with SRAM, which is just a latch; consequently it can be clocked at the same rate as the CPU, whereas DRAM is limited to about 1 GHz while maintaining reasonable power consumption. This causes DRAM to have a higher inherent latency than SRAM, which makes it not worthwhile to use for all but the very largest caches, where the reduced miss rate will pay off. (Haswell and POWER8 are roughly contemporaneous and both incorporate up to 128MB of eDRAM, which is used as an L4 cache.)

Also, as far as latency is concerned, a large part of the difficulty is the physical distance signals must travel. Light can only travel 10 cm in the clock period of a 3 GHz CPU. Of course, signals do not travel in straight lines across the die and nor do they propagate at anything close to the speed of light due to the need for buffering and fan-out, which incur propagation delays. So, the maximum distance a memory can be away from a CPU in order to maintain 1 clock cycle of latency is a few centimetres at most, limiting the amount of memory that can be accommodated in the available area. Intel's Nehalem processor actually reduced the capacity of the L2 cache versus Penryn partly to improve its latency, which led to higher performance.* If we do not care so much about latency, then there is no reason to put the memory on-package, rather than further away where it is more convenient.

It should also be noted that the cache hit rate is very high for most workloads: well above 90% in almost all practical cases, and not uncommonly even above 99%. So, the benefit of including larger memories on-die is inherently limited to reducing the impact of this few percent of misses. Processors intended for the enterprise server market (such as POWER) typically have enormous caches and can profitably include eDRAM because it is useful to accommodate the large working sets of many enterprise workloads. Haswell has it to support the GPU, because textures are large and cannot be accommodated in cache. These are the use cases for eDRAM today, not typical desktop or HPC workloads, which are very well served by the typical cache hierarchies.

To address some issues raised in comments:

These eDRAM caches cannot be used in place of main memory because they are designed as L4 victim caches. This means that they are volatile and effectively content-addressable, so that data stored in them is not treated as residing in any specific location, and may be discarded at any time. These properties are difficult to reconcile with the requirement of RAM to be direct-mapped and persistent, but to change them would make the caches useless for their intended purpose. It is of course possible to embed memories of a more conventional design, as it is done in microcontrollers, but this is not justifiable for systems with large memories since low latency is not as beneficial in main memory as it is in a cache, so enlarging or adding a cache is a more worthwhile proposition.

As to the possibility of very large caches with capacity on the order of gigabytes, a cache is only required to be at most the size of the working set for the application. HPC applications may deal with terabyte datasets, but they have good temporal and spatial locality, and so their working sets typically are not very large. Applications with large working sets are e.g. databases and ERP software, but there is only a limited market for processors optimized for this sort of workload. Unless the software truly needs it, adding more cache provides very rapidly diminishing returns. Recently we have seen processors gain prefetch instructions, so caches are able to be used more efficiently: one can use these instructions to avoid misses caused by the unpredictability of memory access patterns, rather than the absolute size of the working set, which in most cases is still relatively small.

*The improvement in latency was not due only to the smaller physical size of the cache, but also because the associativity was reduced. There were significant changes to the entire cache hierarchy in Nehalem for several different reasons, not all of which were focused on improving performance. So, while this suffices as an example, it is not a complete account."

2nd comment:

"The main reasons larger memory (GB's of DRAM) isn't included on the CPU die itself is primarily about cost. CPU die space is significantly more expensive because of the manufacturing process required to make the very small features. It may also not be possible to manufacture the two on the same die, though I don't know enough about the details to give any definitive answer here.

Let's evaluate the feasibility of putting a large amount of DRAM directly onto the CPU die.

To give a comparison of scale, a modern CPU die might be ~180 mm2
 (approx. size of Intel Haswell dies). I don't have any accurate figures for CPU DRAM die sizes, but let's assume that 1GB of traditional DRAM takes 140mm2
 (calculated from GPU DRAM sizes). To a first order approximation, you are roughly doubling the CPU die size, which means at least doubling the cost of a CPU, and likely more just for 1GB of DRAM on the same die... I am not paying several hundred dollars just to get 1GB of DRAM, and I don't think anyone would.

However, the idea of sticking memory closer to the CPU is not completely a lost cause. This is likely where memory will move in the future because the fact is the speed of light is finite and it is only possible to communicate so fast over a certain distance.

Realistic techniques for moving memory closer to the CPU (note that these also have trade-offs with traditional techniques):

Stack them on top of the CPU itself. This is already done on the Raspberry Pi, and is part of the Wide I/O memory standard. The memory is still a separate die manufactured on a separate process. However, this has the problem that any heat dissipated in the CPU must pass through the memory before reaching a heat sink. This means it won't work for high power processors, and why the primary applications for this technology is in mobile processors/other embedded applications where your CPU isn't consuming many tens or hundreds of watts.

Stick them really close by on a lower-cost substrate. This is how HBM is designed to work, with a very large bus manufactured onto a lower-cost "interposer" die, and is the direction high-end GPU memory is going because the bandwidth is significantly higher. The memory chips and interposer are all still manufactured on different dies from the actual processor."

My response:

The economics makes sense for small chip sizes with low transistor sizes. large chips today regularly have L2 cache exceeding 64-96MB.

Developing a 1990's era 486 (1.2million)  or P54C with it 16MB or 32MB is nothing like the hse case that the question was most likely posed at: 4GB-8GB DDR4 modules. Fitting these on the same die would increase the risk of defects and decrease yields (as one mentioned- 199 out of 10,000 chips instead of 100/10,0000.

However, considering the cost benefits and economies of scale, improving a manufacturing process to support both memory and logic could significantly decrease the PCB cost and latency, particularly with a side by side HBM design: 4MB=CPU=4MB. This would also avoid the heat transfer of the CPU through the memory on the vertically stacked Raspberry Pi.

Silicon manufacturing is Freakonomics. Binning makes economic sense because the foundry and chip designer invested so much into the design. But one needn't bin when there is so much less die space used. It would be hard not to find a margin of profit if far more chips could be manufactured that include noth RAM, GPU, and CPU. Even if they sell a low cost product like the Nokia 225 (with Unisoc). The volume to produce thousands of these chips once the manufacturing process were perfected could result in 98-99% yields.

a 300mm wafer is :

"The following table provides an overview comparison between these wafer sizes:
Attribute	200mm	300mm
Maximum Die per Wafer	100-125 dies	229-450 dies
Die Size Range	20mm2 - 320mm2	60mm2 - 450mm2
Fabrication Maturity	High	Requires advanced expertise
Startup Costs	Low	Very high

https://waferpro.com/200mm-wafer-vs-300mm-wafer/

It's unclear if 300mm wafers need 60mm^2 or 20mm^2 for 200mm wafers or of it just the typical size used for foundry chips produced in high volume. However, a 20mm^2 would be around 7 million x 20, or 140 million transistors using the Haswell estimate. maybe enough for 128MB RAM. 

For 1mmx1mm, though, the economics makes a lot of sense, if there was a will for the product. If not, for science.

But not every customer knows what they need/want. And Steve Jobs said that was the rrason he designed the Mac.

"If I asked customers what they wanted, they would have said they wanted a faster horse!" 
(he was quoting Henry Ford)

Industry Titans aside, the performance of a 486 or 386 with RAM side by side the CPU might actually run faster than the original 1985 design because the vias and routing was significantly further away and may not have reached it's theoretical maximum.

I am still interested in a 40-50MHz clock speed. Even of the DRAM uses much more power than SRAM, it might be possible to keep the power consumption to 2-10mW.

The Claremont had 6 million transistors. Assuming the level shifters were just to downregulate the speed and not needed for a fixed speed, that could suggest it used as little as 3.1 million as the original Pentium in a 60MHz static frequency.

Thus DRAM being similar to logic transistors, might consume 5 mW for 3MB of RAM at 60MHz.

A 386 @33MHz with 275,000 transistors and 4MB of RAM might also consume 5mW or less at 22nm FD-SOI/TSMC ULL/Intel 16nm FF.

https://www.reddit.com/r/LinusTechTips/comments/1d9cyhm/with_cpu_manufacturers_putting_memory_directly_on/?rdt=34560

"@LesserHedgehog There's a limit to how much your cache hit rate can be in general, so adding more cache doesn't really help anything. Also a lot of CPUs actually DO have embedded DRAM now, especially in the mobile/embedded space (many ARM-based SoCs for example). – 
fluffy
 CommentedJun 16, 2015 at 7:47"

 IMG_20250401_143654 - Copy.jpg
https://www.jeffgeerling.com/blogs/jeff-geerling/raspberry-pi-zero-power
JPEG Image - 435.15 kB - 04/01/2025 at 19:43

Preview
IMG_20250401_141252 - Copy.jpg
https://www.waveshare.com/solar-power-manager.htm Solar Power Management Module, for 6V~24V Solar Panel "500mAh 14500 Rechargeable Lithium Battery, High-Capacity 3.7-4.2V, Stainless Steel, 1000+ Cycles, Reliable Power for Electronics"
JPEG Image - 1.22 MB - 04/01/2025 at 19:25

https://hackaday.io/project/177716/gallery#df73ed3e67179b63bf890473e28bee06

Perhaps reusing established form factors, 14500 and 18650 battery form factors for Lithium Ion Capacitors:
https://www.licaptech.com/pdfs/datasheets/lithium-ion/LICAP_LIC_Summary.pdf 
https://www.licaptech.com/products/lc0200-380-asw-lithium-ion-capacitor 200F is 18650 compatible (although tabless). Perhaps a solar power manager with a 14500 could be designed, or a waveshare-like manager with a battery slot could be integrated to support 18650.
Preview 

Wasn't it Bill Gates who said 64mAh ought to be enough for anybody?

The evolution of embedded DRAM (eDRAM)
--

![image](https://github.com/user-attachments/assets/cd9bfa3f-a135-4441-902c-2ce4b44896f2) (2014)
from:
https://semiengineering.com/the-power-of-edram/ 

https://chipworksrealchips.blogspot.com/2014/02/intels-e-dram-shows-up-in-wild.html

https://marklapedus.substack.com/p/leti-quobly-describe-new-fd-soi-devices 

https://ieeexplore.ieee.org/document/9180997 

https://ieeexplore.ieee.org/document/5090590

https://www.blog.baldengineering.com/2020/05/ibm-has-adopted-14-nm-fd-soi-finfet.html

https://marklapedus.substack.com/p/leti-quobly-describe-new-fd-soi-devices

https://semiwiki.com/semiconductor-manufacturers/tsmc/283868-tsmc-32mb-embedded-stt-mram-at-isscc2020/ 

"This implementation in TSMC’s 22nm Ultra-Low-Leakage (ULL) CMOS process has a very high read speed of 10ns, and read power of 0.8mA/MHz-bit. It has 100K cycle write endurance for 32Mb code and 1M cycle endurance for 1Mb data. It supports data retention for IR reflow at 260C of 90 seconds and 10 years data retention at 150C.  It is implemented in a  very small 1transistor-1resistor (1T1R) 0.046 mm2 bit cell and has a very low leakage current of 55mA at 25C for the 32Mb array equivalent to 1.7E-12A/bit when in Low Power Standby Mode (LPSM).  It utilizes a sensing scheme with per-sense amp trimming and 1T4R reference cell." (2020)

![image](https://github.com/user-attachments/assets/0d0b35f7-ab66-4fae-95ca-27e8fe3e2601)

55mA is quite a bit of power. Perhaps the newer technology doesn't use as much..

However, it's unclear what speed that refers to. 100MHz? 10MHz? Does it scale from 1MHz to 100MHz? 0.8Amps x 10MHz = 8mA. A 386 could be clocked from 16MHz or 20MHz. If the memory were clocked at 20MHz, it would consume 16mA at 100% utilization, per 4MB. I'm unsure if this is close to the actual amount, or whether the RAM usage is usually far less on average. But it may be quite reasonable for some systems that are not run constantly. 

https://www.techbriefs.com/component/content/article/6131-z-ram

https://www.ramxeed.com/products/feram/why-feram.html 

https://www.semanticscholar.org/paper/A-22nm-high-performance-embedded-DRAM-SoC-featuring-Brain-Baran/fca85359c455fe6cd03070f15ff084b3798d491f 

https://en.wikipedia.org/wiki/1T-SRAM

Haswell eDRAM (2014) https://www.anandtech.com/Gallery/Album/3392#4 

https://www.techinsights.com/blog/memory/disruptive-technology-tsmc-22ull-emram

https://www.mdpi.com/2076-3417/11/23/11254 

https://cmosedu.com/jbaker/papers/talks/Franklin_Institute_Dennard_Talk.pdf

https://www.eetimes.com/intels-embedded-dram-new-era-of-cache-memory/2/ 

Chip idea:
--

A solar circuit is not an intrinsically solar "capable" circuit. It is indistinguishable from any other CMOS microprocessor transistor. However, the nomenclature is used to emphasize solar capable microprocessors, one designed to be coupled with a proportional amount of photovoltaic panel sizes, and ones that are not oversized. 

![image](https://github.com/user-attachments/assets/73e5c620-cf48-49ba-a086-5aaa9bd32443)

Power saving technique? A standby mode for 2nd 4MB module when RAM utilization <4MB?

As recognized earlier,

"The Haswell E at 22nm is 2.6 billion transistors in 355 mm^2. Dividing 2.6b/ 355 and I get 7.32million transistors:
https://en.m.wikipedia.org/wiki/Transistor_count (or should I do the square root= ~18 x 18)? 

That can't be right, right? 

But that suggests I can fit a Pentium with 8MB DRAM.in 2mm^2 or a 386 with 4MB RAM in 1mm ^2"

7.32 million transistors isn't enough for  a 386 and 8MB of memory, assuming that is the limit for 1mm^2. However, 18nm FDSOI exists, and smaller transistors may be able to fit. But it might be enough for 6MB of RAM! It's also possible that different types of low leakage transistors, even if they are 1T/1C occupy more space than a conventional DRAM transistor, or that the insulating material requires more space. Also, some minimum space between the CPU and RAM may be needed, along with the VRAM and i/o and cache.

In a large volume order, slightly larger than 1 square mm might not make a difference if the reticle can segment each die to larger than 1mm^2 (e.g. 1.25mm^2) per chip https://en.wikichip.org/wiki/mask

https://www.musesemi.com/full-block-tapeout-pricing 

https://www.wired.com/2009/08/ff-goodenough/

https://spectrum.ieee.org/enerj-the-language-of-goodenough-computing

https://en.m.wikipedia.org/wiki/Principle_of_good_enough

https://cacm.acm.org/news/is-good-enough-computing-good-enough/

https://rhombus-tech.net/whitepapers/ecocomputing_07sep2015/

https://ldstephens.net/2024/02/12/good-enough-computing/

February 2025 prepublication, not peer reviewed paper [available here](https://github.com/hatonthecat/solarcircuits/blob/main/A%20Heuristic%20Method%20for%20Designing%20Solar%20Circuits.pdf)

https://www.youtube.com/watch?v=sxeRCpg9mfc 1999 Toshiba Portege, 64MB RAM and Pentium II running Tiny Core Linux with kernel 6.8, excellent performance

DSL 2024 on PIII w/ 512MB RAM: https://www.youtube.com/watch?v=fhOpJwTzFag

https://www.youtube.com/watch?v=BnQqnQiFDTA MX Linux on a Pentium IV

on 2GB RAM (utilization peaks 600<x>512MB) https://www.youtube.com/watch?v=zl7s6RDbuzU

https://en.wikipedia.org/wiki/WinChip 

The WinChip series is a discontinued low-power Socket 7-based x86 processor that was designed by Centaur Technology and marketed by its parent company IDT.

Overview
Design
The design of the WinChip was quite different from other processors of the time. Instead of a large gate count and die area, IDT, using its experience from the RISC processor market, created a small and electrically efficient processor similar to the 80486, because of its single pipeline and in-order execution microarchitecture. It was of much simpler design than its Socket 7 competitors, such as AMD K5/K6, which were superscalar and based on dynamic translation to buffered micro-operations with advanced instruction reordering (out of order execution). 

Performance
Although the small die size and low power-usage made the processor notably inexpensive to manufacture, it never gained much market share. WinChip C6 was a competitor to the Intel Pentium and Pentium MMX, Cyrix 6x86, and AMD K5/K6. It performed adequately, but only in applications that used little floating point math. Its floating point performance was simply well below that of the Pentium and K6, being even slower than the Cyrix 6x86.[4]

Decline
The industry's move away from Socket 7 and the release of the Intel Celeron processor signalled the end of the WinChip. In 1999, the Centaur Technology division of IDT was sold to VIA. Although VIA branded the processors as "Cyrix", the company initially used technology similar to the WinChip in its Cyrix III line.[5]"

Solar RISC
--


https://github.com/user-attachments/assets/43f1a9f8-71da-4a7b-a702-6393597f0c61

Circuit Design
--

https://brandonli.net/semisim/ 
reference material https://hackaday.com/2025/05/13/simulating-high-side-bootstrap-circuits-with-ltspice/

https://semianalysis.com/2022/06/10/apple-m2-die-shot-and-architecture/ (replace this with an x86 and add 16MB eDRAM: https://www.youtube.com/watch?v=p54U74E4eas&feature=youtu.be

<img width="838" height="404" alt="image" src="https://github.com/user-attachments/assets/87a3e5fd-bee8-484f-a270-08da1fa76058" />

 <img width="1024" height="165" alt="image" src="https://github.com/user-attachments/assets/e2f7741b-ae8b-4826-a04c-72d460dc61f9" />

https://github.com/hatonthecat/linux_distro_tests#kolibri-os 8MB RAM w/ Kolibri 16 color https://www.youtube.com/watch?v=c-nL0IOH8nc


1mm^2 chip with 10um kerf width would allow up to 81 chips in a 100mm^2 wafer die space. https://semiengineering.com/laser-ablation-dicing-revolutionizes-ultra-thin-wafer-saws-beyond-the-capability-of-blade-dicing/

10um = 0.01 millimeters.
100um - 0.10 millimeters.

More than 100um kerfs would result in less than eighty one 1mm^2 chips in 100mm^2.

https://www.viksnewsletter.com/p/a-close-look-at-sram-for-inference 

In general, when it comes to capacity, all DRAM technologies whether HBM, LPDDR, or GDDR have an advantage over SRAM. The fundamental difference in their cell structure, as we saw above, directly affects how much memory can be packed into a given die area. With HBM3e, density is on the order of ~200 Mb of DRAM per mm², while at TSMC’s N3E node, 1 mm² of silicon can hold only ~38 Mb of SRAM.

https://datasheet.octopart.com/CG82NM10-S-LGXX-Intel-datasheet-76215416.pdf 

https://www.intel.com/pressroom/enhanced/atom_n450/pdfs/Next_Gen_Atom_Processor_factsheet.pdf?iid=pr_smrelease_Pinetrail_rellinks6

The NM10 integrated Intel 3150 video graphics with an Atom N450 on 45nm High-k Metal Gate technology.  What if this same concept were applied to Pentium era chipsets, like the P54C, with a Cirrus Logic or Tseng EX4000 video card. ALl of this would be integrated, potentially on the same lithography run, without ISA or PCI-express busses, of course. And up to 24MB of RAM is the current memory density of HBM. As to whether the power consumption would be too significant, eDRAM might use less, with 2D stacking. It's also unclear how many pinouts would be needed, although things like USB and SDHC controllers could also be integrated in 1mm^2.




https://inavoyage.blogspot.com/2025/09/the-future-of-32-bit-linux-support.html 
